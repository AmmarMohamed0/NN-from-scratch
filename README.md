# NN-from-scratch
## Neural Network Implementation

This repository contains a simple implementation of a neural network with a dense layer using ReLU activation followed by another dense layer using Softmax activation. The network is tested on the spiral dataset.

### Code Overview

- `layer_Dense` class: Represents a dense layer in the neural network.
- `Activation_ReLU` class: Implements the ReLU activation function.
- `Activation_Softmax` class: Implements the Softmax activation function.

### Usage

1. Install the necessary dependencies:

   ```bash
   pip install nnfs numpy

